{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b39d89",
   "metadata": {},
   "source": [
    "# Complete ML Workflow: Synthetic Data → Training → Analysis\n",
    "## End-to-end pipeline for sinus segmentation and quantitative analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe94ab63",
   "metadata": {},
   "source": [
    "## Step 1: Generate Synthetic Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234924d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 50 synthetic training samples with varied pathology\n",
    "!python ../src/synthetic_generator.py \\\n",
    "    --output-dir ../data/synthetic \\\n",
    "    --num-samples 50 \\\n",
    "    --pathology mixed \\\n",
    "    --severity mixed \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be7d1e",
   "metadata": {},
   "source": [
    "## Step 2: Visualize Synthetic Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc7aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Load a few synthetic samples\n",
    "synthetic_dir = Path('../data/synthetic')\n",
    "image_files = sorted((synthetic_dir / 'images').glob('*.nii.gz'))[:6]\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "\n",
    "for idx, img_path in enumerate(image_files):\n",
    "    # Load image and mask\n",
    "    img = nib.load(str(img_path))\n",
    "    volume = img.get_fdata()\n",
    "    \n",
    "    mask_path = synthetic_dir / 'masks' / img_path.name\n",
    "    mask = nib.load(str(mask_path)).get_fdata()\n",
    "    \n",
    "    # Get middle slice\n",
    "    mid_slice = volume.shape[0] // 2\n",
    "    \n",
    "    # Display image\n",
    "    axes[idx, 0].imshow(volume[mid_slice], cmap='gray', vmin=-1000, vmax=400)\n",
    "    axes[idx, 0].set_title(f'{img_path.stem[:30]}')\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    # Display mask\n",
    "    axes[idx, 1].imshow(mask[mid_slice], cmap='Reds')\n",
    "    axes[idx, 1].set_title('Mask')\n",
    "    axes[idx, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nGenerated {len(list((synthetic_dir / 'images').glob('*.nii.gz')))} synthetic training samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87c3e88",
   "metadata": {},
   "source": [
    "## Step 3: Train MONAI 3D U-Net\n",
    "**Note**: This requires GPU for reasonable training time. Adjust `max_epochs` in config for quick testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7845fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (uncomment to run - this will take time!)\n",
    "# !python ../src/train_segmentation.py \\\n",
    "#     --config ../configs/monai_unet_config.yaml \\\n",
    "#     --data-dir ../data/synthetic \\\n",
    "#     --output-dir ../models/sinus_unet_v1 \\\n",
    "#     --train-split 0.8 \\\n",
    "#     --seed 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f3397b",
   "metadata": {},
   "source": [
    "## Step 4: Run Inference on Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a trained model at models/sinus_unet.pth\n",
    "# Run the full pipeline with segmentation\n",
    "\n",
    "!python ../src/pipeline.py \\\n",
    "    --dicom-dir ../data/raw/5301/5303 \\\n",
    "    --output-nifti ../data/processed/patient_5301_ct.nii.gz \\\n",
    "    --mask-output ../data/processed/patient_5301_mask.nii.gz \\\n",
    "    --metadata-json ../docs/patient_5301_meta.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273be628",
   "metadata": {},
   "source": [
    "## Step 5: Quantitative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive quantitative analysis\n",
    "!python ../src/quantitative_analysis.py \\\n",
    "    --image ../data/processed/sinus_ct.nii.gz \\\n",
    "    --output ../docs/metrics/quantitative_report.json \\\n",
    "    --patient-id 19420531 \\\n",
    "    --study-date 20250418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2773fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the report\n",
    "import json\n",
    "\n",
    "with open('../docs/metrics/quantitative_report.json') as f:\n",
    "    report = json.load(f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUANTITATIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vol = report['volumetric']\n",
    "print(f\"\\nTotal Sinus Volume: {vol['total_sinus_volume_ml']:.2f} mL\")\n",
    "print(f\"Air Volume: {vol['air_volume_ml']:.2f} mL\")\n",
    "print(f\"Soft Tissue Volume: {vol['soft_tissue_volume_ml']:.2f} mL\")\n",
    "print(f\"Air Fraction: {vol['air_fraction']:.1%}\")\n",
    "\n",
    "if report['texture']:\n",
    "    tex = report['texture']\n",
    "    print(f\"\\nTexture Features:\")\n",
    "    print(f\"  Mean HU: {tex['mean_intensity']:.2f}\")\n",
    "    print(f\"  Std HU: {tex['std_intensity']:.2f}\")\n",
    "    print(f\"  Entropy: {tex['entropy']:.3f}\")\n",
    "\n",
    "if report['asymmetry_score']:\n",
    "    print(f\"\\nAsymmetry Score: {report['asymmetry_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd676eb",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Results in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4478c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate interactive 3D mesh\n",
    "!python ../src/visualize_3d.py \\\n",
    "    --nifti ../data/processed/sinus_ct.nii.gz \\\n",
    "    --iso -350 \\\n",
    "    --downsample 2 \\\n",
    "    --output ../docs/sinus_visualization.html\n",
    "\n",
    "print(\"\\n3D visualization saved! Open ../docs/sinus_visualization.html in a browser.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc02bc7",
   "metadata": {},
   "source": [
    "## Step 7: Longitudinal Tracking Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89471b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compare multiple timepoints\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume we have multiple reports (you would generate these from different scans)\n",
    "metrics_dir = Path('../docs/metrics')\n",
    "report_files = sorted(metrics_dir.glob('*_report.json'))\n",
    "\n",
    "if len(report_files) > 0:\n",
    "    # Compile metrics into DataFrame\n",
    "    data = []\n",
    "    for report_file in report_files:\n",
    "        with open(report_file) as f:\n",
    "            r = json.load(f)\n",
    "            data.append({\n",
    "                'date': r['study_date'],\n",
    "                'patient_id': r['patient_id'],\n",
    "                'air_volume_ml': r['volumetric']['air_volume_ml'],\n",
    "                'tissue_volume_ml': r['volumetric']['soft_tissue_volume_ml'],\n",
    "                'air_fraction': r['volumetric']['air_fraction'],\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sort_values('date')\n",
    "    \n",
    "    # Plot trend\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    axes[0].plot(df['date'], df['air_volume_ml'], 'o-', linewidth=2, markersize=8)\n",
    "    axes[0].set_xlabel('Study Date')\n",
    "    axes[0].set_ylabel('Air Volume (mL)')\n",
    "    axes[0].set_title('Sinus Air Volume Over Time')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(df['date'], df['air_fraction'] * 100, 'o-', color='coral', linewidth=2, markersize=8)\n",
    "    axes[1].set_xlabel('Study Date')\n",
    "    axes[1].set_ylabel('Air Fraction (%)')\n",
    "    axes[1].set_title('Air Fraction Trend')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nLongitudinal tracking data:\")\n",
    "    print(df.to_string(index=False))\n",
    "else:\n",
    "    print(\"No multiple timepoint reports found yet. Run analysis on multiple scans to enable tracking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071f1fbd",
   "metadata": {},
   "source": [
    "## Next Steps & Research Directions\n",
    "\n",
    "### Immediate:\n",
    "1. **Collect more real data**: Process all DICOM series in `data/raw/5301/` directories\n",
    "2. **Augment training**: Combine synthetic + real data for better generalization\n",
    "3. **Validate segmentation**: Compare model predictions with radiologist annotations\n",
    "\n",
    "### ML Improvements:\n",
    "4. **Multi-class segmentation**: Separate labels for each sinus (maxillary, frontal, ethmoid, sphenoid)\n",
    "5. **Transfer learning**: Fine-tune from pre-trained medical imaging models\n",
    "6. **Ensemble methods**: Combine multiple models for robust predictions\n",
    "\n",
    "### Clinical Analysis:\n",
    "7. **Literature comparison**: Compare your metrics with published normal ranges\n",
    "8. **Ostiomeatal complex analysis**: Quantify critical drainage pathways\n",
    "9. **Correlation studies**: Link metrics to symptoms (congestion, headache, etc.)\n",
    "\n",
    "### Automation:\n",
    "10. **Dashboard creation**: Build Streamlit/Dash app for easy analysis\n",
    "11. **Reporting templates**: Auto-generate medical reports with visualizations\n",
    "12. **Integration**: Connect with PACS systems for clinical deployment"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
