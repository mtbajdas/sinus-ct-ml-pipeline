{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6757a8",
   "metadata": {},
   "source": [
    "# Sinus CT Data Exploration\n",
    "## Initial analysis of CT volume characteristics and preparation for ML modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeaa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c333ba",
   "metadata": {},
   "source": [
    "## Load CT Volume and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40556b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed NIfTI\n",
    "nifti_path = Path('../data/processed/sinus_ct.nii.gz')\n",
    "img = nib.load(str(nifti_path))\n",
    "volume = img.get_fdata().astype(np.float32)\n",
    "spacing = img.header.get_zooms()[:3]\n",
    "\n",
    "# Load metadata\n",
    "with open('../docs/last_run_meta.json') as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "print(f\"Volume shape: {volume.shape}\")\n",
    "print(f\"Voxel spacing: {spacing} mm\")\n",
    "print(f\"Physical dimensions: {[s*d for s,d in zip(volume.shape, spacing)]} mm\")\n",
    "print(f\"Study date: {meta['study_date']}\")\n",
    "print(f\"HU range: [{volume.min():.1f}, {volume.max():.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e820329",
   "metadata": {},
   "source": [
    "## Intensity Distribution Analysis\n",
    "Understanding HU distribution is critical for segmentation thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histogram of HU values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Full range histogram\n",
    "axes[0].hist(volume.flatten(), bins=100, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Hounsfield Units')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Full HU Distribution')\n",
    "axes[0].axvline(-1000, color='red', linestyle='--', label='Air', alpha=0.7)\n",
    "axes[0].axvline(0, color='green', linestyle='--', label='Water/Soft tissue', alpha=0.7)\n",
    "axes[0].legend()\n",
    "\n",
    "# Focus on sinus-relevant range [-1000, 400]\n",
    "sinus_range = volume[(volume >= -1000) & (volume <= 400)]\n",
    "axes[1].hist(sinus_range.flatten(), bins=100, alpha=0.7, color='coral', edgecolor='black')\n",
    "axes[1].set_xlabel('Hounsfield Units')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Sinus-Relevant Range [-1000, 400] HU')\n",
    "axes[1].axvline(-400, color='purple', linestyle='--', label='Air cavity threshold', alpha=0.7)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate key statistics\n",
    "print(f\"\\nKey Statistics:\")\n",
    "print(f\"  Mean HU: {volume.mean():.1f}\")\n",
    "print(f\"  Std HU: {volume.std():.1f}\")\n",
    "print(f\"  Air voxels (< -400 HU): {(volume < -400).sum() / volume.size * 100:.2f}%\")\n",
    "print(f\"  Soft tissue voxels (-100 to 100 HU): {((volume > -100) & (volume < 100)).sum() / volume.size * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f3218",
   "metadata": {},
   "source": [
    "## Anatomical Slice Visualization\n",
    "Examine axial, sagittal, and coronal views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5dca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select middle slices\n",
    "mid_axial = volume.shape[0] // 2\n",
    "mid_sagittal = volume.shape[1] // 2\n",
    "mid_coronal = volume.shape[2] // 2\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Axial (head-to-feet)\n",
    "axes[0].imshow(volume[mid_axial, :, :], cmap='gray', vmin=-1000, vmax=400)\n",
    "axes[0].set_title(f'Axial Slice {mid_axial}')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Sagittal (left-to-right)\n",
    "axes[1].imshow(volume[:, mid_sagittal, :], cmap='gray', vmin=-1000, vmax=400)\n",
    "axes[1].set_title(f'Sagittal Slice {mid_sagittal}')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Coronal (front-to-back)\n",
    "axes[2].imshow(volume[:, :, mid_coronal], cmap='gray', vmin=-1000, vmax=400)\n",
    "axes[2].set_title(f'Coronal Slice {mid_coronal}')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c36e0fe",
   "metadata": {},
   "source": [
    "## Air Cavity Segmentation (Baseline)\n",
    "Simple threshold-based segmentation to identify nasal/sinus air spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e9ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for air cavities\n",
    "air_threshold = -400  # HU\n",
    "air_mask = volume < air_threshold\n",
    "\n",
    "# Remove small noise with morphological operations\n",
    "from scipy.ndimage import binary_opening, binary_closing\n",
    "air_mask_clean = binary_opening(air_mask, structure=np.ones((3, 3, 3)))\n",
    "air_mask_clean = binary_closing(air_mask_clean, structure=np.ones((5, 5, 5)))\n",
    "\n",
    "# Calculate air volume\n",
    "voxel_volume_mm3 = np.prod(spacing)\n",
    "air_volume_mm3 = air_mask_clean.sum() * voxel_volume_mm3\n",
    "air_volume_ml = air_volume_mm3 / 1000\n",
    "\n",
    "print(f\"Detected air cavity volume: {air_volume_ml:.2f} mL\")\n",
    "print(f\"Air cavity voxels: {air_mask_clean.sum()}\")\n",
    "print(f\"Air fraction: {air_mask_clean.sum() / volume.size * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ec810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize air segmentation overlay\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "slices = [mid_axial - 20, mid_axial, mid_axial + 20]\n",
    "for i, slice_idx in enumerate(slices):\n",
    "    # Original\n",
    "    axes[0, i].imshow(volume[slice_idx, :, :], cmap='gray', vmin=-1000, vmax=400)\n",
    "    axes[0, i].set_title(f'Original - Slice {slice_idx}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Overlay air mask\n",
    "    axes[1, i].imshow(volume[slice_idx, :, :], cmap='gray', vmin=-1000, vmax=400)\n",
    "    axes[1, i].imshow(air_mask_clean[slice_idx, :, :], cmap='Reds', alpha=0.4)\n",
    "    axes[1, i].set_title(f'Air Segmentation - Slice {slice_idx}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797d430",
   "metadata": {},
   "source": [
    "## Region of Interest (ROI) Analysis\n",
    "Identify sinus regions for focused training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import label\n",
    "\n",
    "# Label connected components\n",
    "labeled_air, num_features = label(air_mask_clean)\n",
    "print(f\"Found {num_features} distinct air cavities\")\n",
    "\n",
    "# Analyze each component\n",
    "component_stats = []\n",
    "for i in range(1, num_features + 1):\n",
    "    component = (labeled_air == i)\n",
    "    volume_ml = component.sum() * voxel_volume_mm3 / 1000\n",
    "    \n",
    "    # Get bounding box\n",
    "    coords = np.where(component)\n",
    "    bbox = [\n",
    "        (coords[0].min(), coords[0].max()),\n",
    "        (coords[1].min(), coords[1].max()),\n",
    "        (coords[2].min(), coords[2].max())\n",
    "    ]\n",
    "    \n",
    "    component_stats.append({\n",
    "        'component': i,\n",
    "        'volume_ml': volume_ml,\n",
    "        'voxels': component.sum(),\n",
    "        'bbox': bbox\n",
    "    })\n",
    "\n",
    "# Sort by volume\n",
    "component_stats.sort(key=lambda x: x['volume_ml'], reverse=True)\n",
    "\n",
    "# Display top 10 largest cavities\n",
    "df = pd.DataFrame(component_stats[:10])\n",
    "print(\"\\nTop 10 Largest Air Cavities:\")\n",
    "print(df[['component', 'volume_ml', 'voxels']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea46514",
   "metadata": {},
   "source": [
    "## Prepare Training Patches\n",
    "Extract 96Â³ patches for MONAI training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab0580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define patch extraction function\n",
    "def extract_patches(volume, mask, patch_size=(96, 96, 96), num_patches=10, foreground_ratio=0.3):\n",
    "    \"\"\"\n",
    "    Extract patches with at least foreground_ratio of mask voxels.\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    mask_patches = []\n",
    "    \n",
    "    # Find valid centers (not too close to edges)\n",
    "    valid_centers = []\n",
    "    for i in range(patch_size[0]//2, volume.shape[0] - patch_size[0]//2, 10):\n",
    "        for j in range(patch_size[1]//2, volume.shape[1] - patch_size[1]//2, 10):\n",
    "            for k in range(patch_size[2]//2, volume.shape[2] - patch_size[2]//2, 10):\n",
    "                # Check if patch has sufficient foreground\n",
    "                patch_mask = mask[\n",
    "                    i-patch_size[0]//2:i+patch_size[0]//2,\n",
    "                    j-patch_size[1]//2:j+patch_size[1]//2,\n",
    "                    k-patch_size[2]//2:k+patch_size[2]//2\n",
    "                ]\n",
    "                if patch_mask.mean() >= foreground_ratio:\n",
    "                    valid_centers.append((i, j, k))\n",
    "    \n",
    "    # Sample random patches\n",
    "    if len(valid_centers) > num_patches:\n",
    "        selected = np.random.choice(len(valid_centers), num_patches, replace=False)\n",
    "        valid_centers = [valid_centers[i] for i in selected]\n",
    "    \n",
    "    for i, j, k in valid_centers:\n",
    "        patch = volume[\n",
    "            i-patch_size[0]//2:i+patch_size[0]//2,\n",
    "            j-patch_size[1]//2:j+patch_size[1]//2,\n",
    "            k-patch_size[2]//2:k+patch_size[2]//2\n",
    "        ]\n",
    "        patch_mask = mask[\n",
    "            i-patch_size[0]//2:i+patch_size[0]//2,\n",
    "            j-patch_size[1]//2:j+patch_size[1]//2,\n",
    "            k-patch_size[2]//2:k+patch_size[2]//2\n",
    "        ]\n",
    "        patches.append(patch)\n",
    "        mask_patches.append(patch_mask)\n",
    "    \n",
    "    return patches, mask_patches\n",
    "\n",
    "# Extract sample patches\n",
    "patches, mask_patches = extract_patches(volume, air_mask_clean, num_patches=5, foreground_ratio=0.2)\n",
    "print(f\"Extracted {len(patches)} training patches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff165ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize patches\n",
    "fig, axes = plt.subplots(len(patches), 3, figsize=(12, 4*len(patches)))\n",
    "if len(patches) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for i, (patch, mask_patch) in enumerate(zip(patches, mask_patches)):\n",
    "    mid = patch.shape[0] // 2\n",
    "    \n",
    "    axes[i, 0].imshow(patch[mid, :, :], cmap='gray', vmin=-1000, vmax=400)\n",
    "    axes[i, 0].set_title(f'Patch {i+1} - Image')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    axes[i, 1].imshow(mask_patch[mid, :, :], cmap='Reds')\n",
    "    axes[i, 1].set_title(f'Patch {i+1} - Mask')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    axes[i, 2].imshow(patch[mid, :, :], cmap='gray', vmin=-1000, vmax=400)\n",
    "    axes[i, 2].imshow(mask_patch[mid, :, :], cmap='Reds', alpha=0.4)\n",
    "    axes[i, 2].set_title(f'Patch {i+1} - Overlay')\n",
    "    axes[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11fd402",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "1. Generate synthetic training data with controlled inflammation patterns\n",
    "2. Train MONAI 3D U-Net on augmented dataset\n",
    "3. Extract PyRadiomics features for longitudinal tracking\n",
    "4. Build comparative analysis against literature values"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
